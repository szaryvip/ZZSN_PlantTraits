{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szaryvip/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import R2Score\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import shutil\n",
    "import os\n",
    "from dataset import PGLSDataset\n",
    "from models import PGLSModel, SimpleTabularModel, EnsemblePGLSModel\n",
    "import timm\n",
    "from torchrec.models import deepfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [\"data/train_images\", \"data/test_images\"]:\n",
    "    if \"0\" not in os.listdir(folder):\n",
    "        print(\"Moving images to 0 folder\")\n",
    "        os.makedirs(f\"{folder}/0\")\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.lower().endswith(\".jpeg\"):\n",
    "                source_path = os.path.join(folder, filename)\n",
    "                target_path = os.path.join(f\"{folder}/0\", filename)\n",
    "\n",
    "                shutil.move(source_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((288, 288)),  # Resize the image to 224x224\n",
    "    transforms.ToTensor(),         # Convert PIL image to tensor (H x W x C) in the range [0.0, 1.0]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "batch_size = 16     # use 4 if problem with GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = 'data/train_images'\n",
    "test_images_path = 'data/test_images'\n",
    "\n",
    "train_csv_path = 'data/train.csv'\n",
    "test_csv_path = 'data/test.csv'\n",
    "\n",
    "\n",
    "tabular_data = pd.read_csv(train_csv_path)\n",
    "targets = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"]\n",
    "\n",
    "# Filter data\n",
    "upper_values = {}\n",
    "for target in targets:\n",
    "    upper_values[target] = tabular_data[target+\"_mean\"].quantile(0.99)\n",
    "    tabular_data = tabular_data[tabular_data[target+\"_mean\"] < upper_values[target]]\n",
    "    tabular_data = tabular_data[tabular_data[target+\"_mean\"] > 0]\n",
    "\n",
    "# Normalize the targets\n",
    "original_means = tabular_data[[f\"{target}_mean\" for target in targets]].mean()\n",
    "original_stds = tabular_data[[f\"{target}_mean\" for target in targets]].std()\n",
    "tabular_data[[f\"{target}_mean\" for target in targets]] = (tabular_data[[f\"{target}_mean\" for target in targets]] - original_means) / original_stds\n",
    "\n",
    "# Normalize the features\n",
    "tabular_input_size = 0\n",
    "for column in tabular_data.columns:\n",
    "    if column in [\"id\"]+[target+\"_mean\" for target in targets]+[target+\"_sd\" for target in targets]:\n",
    "        continue\n",
    "    tabular_input_size += 1\n",
    "    min_val = tabular_data[column].min()\n",
    "    max_val = tabular_data[column].max()\n",
    "    tabular_data[column] = (tabular_data[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "test_tabular_data = pd.read_csv(test_csv_path)\n",
    "# Normalize the features\n",
    "for column in test_tabular_data.columns:\n",
    "    if column in [\"id\"]:\n",
    "        continue\n",
    "    min_val = test_tabular_data[column].min()\n",
    "    max_val = test_tabular_data[column].max()\n",
    "    test_tabular_data[column] = (test_tabular_data[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "train_images_dataset = ImageFolder(root=train_images_path, transform=transform)\n",
    "test_images_dataset = ImageFolder(root=test_images_path, transform=transform)\n",
    "\n",
    "train_image_csv_dataset = PGLSDataset(tabular_data=tabular_data, image_folder=train_images_dataset, transform_csv=None)\n",
    "train, val = random_split(train_image_csv_dataset, [int(0.8*len(train_image_csv_dataset)), len(train_image_csv_dataset) - int(0.8*len(train_image_csv_dataset))])\n",
    "test_image_csv_dataset = PGLSDataset(tabular_data=test_tabular_data, image_folder=test_images_dataset, transform_csv=None)\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_image_csv_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stds = torch.from_numpy(original_stds.values).float()\n",
    "original_means = torch.from_numpy(original_means.values).float()\n",
    "def denormalize_targets(targets):\n",
    "    return targets * original_stds + original_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effnet = efficientnet_b0(weights=EfficientNet_B0_Weights)\n",
    "effnet = timm.create_model(\n",
    "    'efficientnet_b3.ra2_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,\n",
    ")\n",
    "\n",
    "# beit = timm.create_model('beit_base_patch16_224', pretrained=True, num_classes=0)\n",
    "tabular_model = SimpleTabularModel(input_data_len=tabular_input_size)\n",
    "model = PGLSModel(effnet, tabular_model)\n",
    "metric = R2Score()\n",
    "criterion = torch.nn.MSELoss()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(image, features)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for data in train_data_loader:\n",
    "        image, features, targets = data\n",
    "        image = image.to(device)\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image, features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        outputs = outputs.to(\"cpu\")\n",
    "        targets = targets.to(\"cpu\")\n",
    "        outputs_denorm = denormalize_targets(outputs)\n",
    "        targets_denorm = denormalize_targets(targets)\n",
    "        metric.update(outputs_denorm, targets_denorm)\n",
    "        print(loss.item())\n",
    "        print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss on validation set:  2.2444624650272433\n",
      "Average R2 on validation set:  -1.1852780087781272\n"
     ]
    }
   ],
   "source": [
    "accumulated_loss = 0\n",
    "iterations = 0\n",
    "accumulated_r2 = 0\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in val_data_loader:\n",
    "        image, features, targets = data\n",
    "        image = image.to(device)\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(image, features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        accumulated_loss += loss.item()\n",
    "        iterations += 1\n",
    "        outputs = outputs.to(\"cpu\")\n",
    "        targets = targets.to(\"cpu\")\n",
    "        outputs_denorm = denormalize_targets(outputs)\n",
    "        targets_denorm = denormalize_targets(targets)\n",
    "        metric.update(outputs_denorm, targets_denorm)\n",
    "        accumulated_r2 += metric.compute().item()\n",
    "print(\"Average loss on validation set: \", accumulated_loss/iterations)\n",
    "print(\"Average R2 on validation set: \", accumulated_r2/iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for data in test_data_loader:\n",
    "        image, features, targets = data\n",
    "        image = image.to(device)\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(image, features)\n",
    "        outputs = outputs.to(\"cpu\")\n",
    "        outputs_denorm = denormalize_targets(outputs)\n",
    "        predictions.append(outputs_denorm)\n",
    "predictions = [item for sublist in predictions for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, test_csv_dataframe, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"id,X4,X11,X18,X26,X50,X3112\\n\")\n",
    "        for pred, id in zip(predictions, test_csv_dataframe[\"id\"]):\n",
    "            pred = [p.item() for p in pred]\n",
    "            f.write(f\"{id},{','.join([str(p) for p in pred])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_predictions\u001b[49m(predictions, test_tabular_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "save_predictions(predictions, test_tabular_data, \"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szaryvip/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/szaryvip/.local/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name ens_adv_inception_resnet_v2 to current inception_resnet_v2.tf_ens_adv_in1k.\n",
      "  model = create_fn(\n",
      "Using cache found in /home/szaryvip/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/szaryvip/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/szaryvip/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "effnet = efficientnet_b0(weights=EfficientNet_B0_Weights).to(device)\n",
    "xception = timm.create_model('ens_adv_inception_resnet_v2', pretrained=True, num_classes=1000).to(device)\n",
    "densenet = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True).to(device)\n",
    "# tabular_model = SimpleTabularModel(input_data_len=tabular_input_size).to(device)\n",
    "tabular_model = deepfm.DenseArch(tabular_input_size, 100, 100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric = R2Score()\n",
    "criterion = torch.nn.MSELoss()\n",
    "ensemble_model = EnsemblePGLSModel([effnet, xception, densenet], tabular_model)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1576093.375\n",
      "tensor(-0.7377)\n",
      "814426.3125\n",
      "tensor(-0.7467)\n",
      "224598.25\n",
      "tensor(-0.7492)\n",
      "219645.1875\n",
      "tensor(-0.7399)\n",
      "906061.8125\n",
      "tensor(-0.7478)\n",
      "1727129.125\n",
      "tensor(-0.7582)\n",
      "2740938.0\n",
      "tensor(-0.7741)\n",
      "707776.0\n",
      "tensor(-0.7634)\n",
      "570188.0625\n",
      "tensor(-0.7529)\n",
      "1051340.5\n",
      "tensor(-0.7540)\n",
      "4920303.0\n",
      "tensor(-0.7655)\n",
      "175716.4375\n",
      "tensor(-0.7743)\n",
      "536888.6875\n",
      "tensor(-0.7874)\n",
      "1362061.375\n",
      "tensor(-0.8085)\n",
      "563966.5\n",
      "tensor(-0.8157)\n",
      "1004468.1875\n",
      "tensor(-0.8150)\n",
      "2490296.5\n",
      "tensor(-0.8166)\n",
      "754982.6875\n",
      "tensor(-0.8152)\n",
      "2201367.0\n",
      "tensor(-0.8136)\n",
      "998583.8125\n",
      "tensor(-0.8164)\n",
      "263361.03125\n",
      "tensor(-0.8233)\n",
      "2644947.75\n",
      "tensor(-0.8234)\n",
      "745026.4375\n",
      "tensor(-0.8286)\n",
      "1524908.375\n",
      "tensor(-0.8477)\n",
      "1759351.5\n",
      "tensor(-0.8605)\n",
      "6308760.0\n",
      "tensor(-0.8643)\n",
      "963321.9375\n",
      "tensor(-0.8605)\n",
      "145856.90625\n",
      "tensor(-0.8639)\n",
      "966126.8125\n",
      "tensor(-0.8628)\n",
      "13082564.0\n",
      "tensor(-0.8755)\n",
      "1459983.0\n",
      "tensor(-0.8878)\n",
      "1750251.625\n",
      "tensor(-0.8867)\n",
      "446590.0\n",
      "tensor(-0.8886)\n",
      "970637.6875\n",
      "tensor(-0.8841)\n",
      "2467010.5\n",
      "tensor(-0.8932)\n",
      "1943586.875\n",
      "tensor(-0.8991)\n",
      "1010202.75\n",
      "tensor(-0.9092)\n",
      "1268271.375\n",
      "tensor(-0.9080)\n",
      "1081339.875\n",
      "tensor(-0.8704)\n",
      "634904.1875\n",
      "tensor(-0.8640)\n",
      "386677.875\n",
      "tensor(-0.8641)\n",
      "979647.4375\n",
      "tensor(-0.8690)\n",
      "1237425.125\n",
      "tensor(-0.8711)\n",
      "1675397.875\n",
      "tensor(-0.8789)\n",
      "322749.59375\n",
      "tensor(-0.8767)\n",
      "5345411.0\n",
      "tensor(-0.8855)\n",
      "1109089.375\n",
      "tensor(-0.8898)\n",
      "3358379.0\n",
      "tensor(-0.8974)\n",
      "161923.234375\n",
      "tensor(-0.9012)\n",
      "8112792.0\n",
      "tensor(-0.8873)\n",
      "711462.4375\n",
      "tensor(-0.8951)\n",
      "2993223.25\n",
      "tensor(-0.8966)\n",
      "496661.65625\n",
      "tensor(-0.8916)\n",
      "12630111.0\n",
      "tensor(-0.8630)\n",
      "973171.5625\n",
      "tensor(-0.8670)\n",
      "2261053.25\n",
      "tensor(-0.8710)\n",
      "495862.21875\n",
      "tensor(-0.8704)\n",
      "1269003.625\n",
      "tensor(-0.8672)\n",
      "1913994.625\n",
      "tensor(-0.8662)\n",
      "466706.03125\n",
      "tensor(-0.8647)\n",
      "4881377.0\n",
      "tensor(-0.8652)\n",
      "3632301.0\n",
      "tensor(-0.8434)\n",
      "339625.75\n",
      "tensor(-0.8457)\n",
      "5107423.5\n",
      "tensor(-0.8469)\n",
      "513668.59375\n",
      "tensor(-0.8523)\n",
      "664027.5625\n",
      "tensor(-0.8491)\n",
      "1196934.625\n",
      "tensor(-0.8473)\n",
      "1841273.375\n",
      "tensor(-0.8425)\n",
      "1602081.375\n",
      "tensor(-0.8506)\n",
      "10476269.0\n",
      "tensor(-0.8477)\n",
      "1862269.125\n",
      "tensor(-0.8441)\n",
      "1165203.375\n",
      "tensor(-0.8433)\n",
      "779746.4375\n",
      "tensor(-0.8360)\n",
      "1462065.875\n",
      "tensor(-0.8307)\n",
      "2041630.375\n",
      "tensor(-0.8335)\n",
      "3354338.0\n",
      "tensor(-0.8290)\n",
      "557463.0\n",
      "tensor(-0.8216)\n",
      "709682.6875\n",
      "tensor(-0.8322)\n",
      "2730667.25\n",
      "tensor(-0.8326)\n",
      "3544756.25\n",
      "tensor(-0.8344)\n",
      "1125394.875\n",
      "tensor(-0.8434)\n",
      "2325019.25\n",
      "tensor(-0.8456)\n",
      "1502112.375\n",
      "tensor(-0.8468)\n",
      "2044159.625\n",
      "tensor(-0.8445)\n",
      "683965.4375\n",
      "tensor(-0.8508)\n",
      "3410634.25\n",
      "tensor(-0.8501)\n",
      "1032211.75\n",
      "tensor(-0.8517)\n",
      "1681480.0\n",
      "tensor(-0.8575)\n",
      "2396015.75\n",
      "tensor(-0.8590)\n",
      "184943.5\n",
      "tensor(-0.8576)\n",
      "438487.875\n",
      "tensor(-0.8570)\n",
      "1587473.0\n",
      "tensor(-0.8591)\n",
      "402614.53125\n",
      "tensor(-0.8623)\n",
      "825736.9375\n",
      "tensor(-0.8642)\n",
      "4842903.5\n",
      "tensor(-0.8731)\n",
      "2093185.125\n",
      "tensor(-0.8731)\n",
      "1140768.625\n",
      "tensor(-0.8758)\n",
      "1311328.875\n",
      "tensor(-0.8783)\n",
      "4477847.5\n",
      "tensor(-0.8875)\n",
      "7293662.5\n",
      "tensor(-0.8743)\n",
      "1650905.875\n",
      "tensor(-0.8658)\n",
      "1904872.375\n",
      "tensor(-0.8613)\n",
      "926130.0625\n",
      "tensor(-0.8647)\n",
      "752924.5\n",
      "tensor(-0.8685)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m targets_denorm \u001b[38;5;241m=\u001b[39m denormalize_targets(targets)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs_denorm, targets_denorm)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m metric\u001b[38;5;241m.\u001b[39mupdate(outputs_denorm, targets_denorm)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ensemble_model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "\n",
    "ensemble_model.train()\n",
    "for epoch in range(2):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for data in train_data_loader:\n",
    "        image, features, targets = data\n",
    "        image = image.to(device)\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ensemble_model(image, features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        outputs = outputs.to(\"cpu\")\n",
    "        targets = targets.to(\"cpu\")\n",
    "        outputs_denorm = denormalize_targets(outputs)\n",
    "        targets_denorm = denormalize_targets(targets)\n",
    "        metric.update(outputs_denorm, targets_denorm)\n",
    "        print(loss.item())\n",
    "        print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
